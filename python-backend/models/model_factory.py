"""
AI Model Factory - OpenRouter Integration
ä½¿ç”¨ OpenRouter API çµ±ä¸€è¨ªå•å¤šå€‹ AI æ¨¡å‹
"""
import os
import requests
from typing import List, Dict, Any, Optional
from termcolor import cprint


class SwarmAgent:
    """
    Swarm Agent - å¤šæ¨¡å‹å…±è­˜é æ¸¬
    ä½¿ç”¨ OpenRouter API è¨ªå•å¤šå€‹ AI æ¨¡å‹ä¸¦ç¶œåˆå…¶è§€é»
    """
    
    def __init__(self, models: List[str]):
        """
        åˆå§‹åŒ– Swarm Agent
        
        Args:
            models: è¦ä½¿ç”¨çš„æ¨¡å‹åˆ—è¡¨ï¼Œä¾‹å¦‚ï¼š
                - "openai/gpt-4o-mini"
                - "anthropic/claude-3.5-haiku"
                - "google/gemini-2.0-flash-exp"
        """
        self.models = models
        self.api_key = os.getenv("OPENROUTER_API_KEY")
        self.api_url = "https://openrouter.ai/api/v1/chat/completions"
        
        if not self.api_key:
            raise ValueError("OPENROUTER_API_KEY not found in environment variables")
        
        cprint(f"ğŸ¤– Swarm Agent initialized with {len(models)} models", "cyan")
        for model in models:
            cprint(f"   â€¢ {model}", "cyan")
    
    def get_consensus(
        self,
        prompt: str,
        system_prompt: str = "You are a helpful assistant.",
        temperature: float = 0.7,
        max_tokens: int = 500
    ) -> Dict[str, Any]:
        """
        ç²å–å¤šæ¨¡å‹å…±è­˜é æ¸¬
        
        Args:
            prompt: ç”¨æˆ¶æç¤º
            system_prompt: ç³»çµ±æç¤º
            temperature: æº«åº¦åƒæ•¸ï¼ˆ0-1ï¼‰
            max_tokens: æœ€å¤§ç”Ÿæˆ token æ•¸
        
        Returns:
            {
                "consensus": "YES" or "NO",
                "confidence": 0.0-1.0,
                "total_models": int,
                "agree_models": int,
                "responses": [
                    {
                        "model": str,
                        "prediction": str,
                        "reasoning": str
                    }
                ]
            }
        """
        responses = []
        predictions = []
        
        # Query each model
        for model in self.models:
            try:
                response = self._call_model(
                    model=model,
                    prompt=prompt,
                    system_prompt=system_prompt,
                    temperature=temperature,
                    max_tokens=max_tokens
                )
                
                # Parse response
                content = response.strip()
                prediction = self._extract_prediction(content)
                
                responses.append({
                    "model": model,
                    "prediction": prediction,
                    "reasoning": content
                })
                predictions.append(prediction)
                
                cprint(f"âœ… {model}: {prediction}", "green")
                
            except Exception as e:
                cprint(f"âŒ Error with {model}: {e}", "red")
                continue
        
        # Calculate consensus
        if not predictions:
            raise Exception("No successful model responses")
        
        yes_count = predictions.count("YES")
        no_count = predictions.count("NO")
        total = len(predictions)
        
        if yes_count > no_count:
            consensus = "YES"
            agree_models = yes_count
        else:
            consensus = "NO"
            agree_models = no_count
        
        confidence = agree_models / total
        
        result = {
            "consensus": consensus,
            "confidence": confidence,
            "total_models": total,
            "agree_models": agree_models,
            "responses": responses
        }
        
        cprint(f"\nğŸ¯ Consensus: {consensus} (Confidence: {confidence:.1%})", "yellow", attrs=['bold'])
        
        return result
    
    def _call_model(
        self,
        model: str,
        prompt: str,
        system_prompt: str,
        temperature: float,
        max_tokens: int
    ) -> str:
        """
        èª¿ç”¨ OpenRouter API
        
        Args:
            model: æ¨¡å‹åç¨±ï¼ˆä¾‹å¦‚ "openai/gpt-4o-mini"ï¼‰
            prompt: ç”¨æˆ¶æç¤º
            system_prompt: ç³»çµ±æç¤º
            temperature: æº«åº¦åƒæ•¸
            max_tokens: æœ€å¤§ token æ•¸
        
        Returns:
            æ¨¡å‹çš„å›æ‡‰æ–‡æœ¬
        """
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://polymarket-insights.com",  # Optional
            "X-Title": "Polymarket Insights"  # Optional
        }
        
        payload = {
            "model": model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ],
            "temperature": temperature,
            "max_tokens": max_tokens
        }
        
        response = requests.post(
            self.api_url,
            headers=headers,
            json=payload,
            timeout=30
        )
        
        if response.status_code != 200:
            raise Exception(f"API Error {response.status_code}: {response.text}")
        
        data = response.json()
        content = data["choices"][0]["message"]["content"]
        
        return content
    
    def _extract_prediction(self, content: str) -> str:
        """
        å¾æ¨¡å‹å›æ‡‰ä¸­æå–é æ¸¬çµæœï¼ˆYES æˆ– NOï¼‰
        
        Args:
            content: æ¨¡å‹å›æ‡‰æ–‡æœ¬
        
        Returns:
            "YES" æˆ– "NO"
        """
        content_upper = content.upper()
        
        # Look for explicit YES/NO at the start
        if content_upper.startswith("YES"):
            return "YES"
        if content_upper.startswith("NO"):
            return "NO"
        
        # Count occurrences
        yes_count = content_upper.count("YES")
        no_count = content_upper.count("NO")
        
        if yes_count > no_count:
            return "YES"
        elif no_count > yes_count:
            return "NO"
        else:
            # Default to YES if unclear
            return "YES"


class SingleModelAgent:
    """
    Single Model Agent - å–®ä¸€æ¨¡å‹é æ¸¬
    é©ç”¨æ–¼ä¸éœ€è¦å…±è­˜çš„å ´æ™¯
    """
    
    def __init__(self, model: str = "openai/gpt-4o-mini"):
        """
        åˆå§‹åŒ– Single Model Agent
        
        Args:
            model: æ¨¡å‹åç¨±ï¼ˆOpenRouter æ ¼å¼ï¼‰
        """
        self.model = model
        self.api_key = os.getenv("OPENROUTER_API_KEY")
        self.api_url = "https://openrouter.ai/api/v1/chat/completions"
        
        if not self.api_key:
            raise ValueError("OPENROUTER_API_KEY not found in environment variables")
        
        cprint(f"ğŸ¤– Single Model Agent initialized: {model}", "cyan")
    
    def get_completion(
        self,
        prompt: str,
        system_prompt: str = "You are a helpful assistant.",
        temperature: float = 0.7,
        max_tokens: int = 500
    ) -> str:
        """
        ç²å–å–®ä¸€æ¨¡å‹çš„å›æ‡‰
        
        Args:
            prompt: ç”¨æˆ¶æç¤º
            system_prompt: ç³»çµ±æç¤º
            temperature: æº«åº¦åƒæ•¸
            max_tokens: æœ€å¤§ token æ•¸
        
        Returns:
            æ¨¡å‹çš„å›æ‡‰æ–‡æœ¬
        """
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://polymarket-insights.com",
            "X-Title": "Polymarket Insights"
        }
        
        payload = {
            "model": self.model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ],
            "temperature": temperature,
            "max_tokens": max_tokens
        }
        
        response = requests.post(
            self.api_url,
            headers=headers,
            json=payload,
            timeout=30
        )
        
        if response.status_code != 200:
            raise Exception(f"API Error {response.status_code}: {response.text}")
        
        data = response.json()
        content = data["choices"][0]["message"]["content"]
        
        return content


# é è¨­æ¨¡å‹é…ç½®
DEFAULT_SWARM_MODELS = [
    "openai/gpt-4o-mini",
    "anthropic/claude-3.5-haiku",
    "google/gemini-2.0-flash-exp:free"
]

DEFAULT_SINGLE_MODEL = "openai/gpt-4o-mini"
